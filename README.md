Модель машинного обучения, разработанная в рамках курсового проекта по предмету "Алгоритмизация и программирование". Представляет собой классификатор для кредитного скоринга, что определяет вероятность выдачи кредита по введенным данным. Используемый алгоритм МО - Random Forest. 

Для того чтобы создать модель, нам требовалось решить, какой именно алгоритм мы выберем за основу будущего классификатора. Изучив данные и зависимости с помощью визуализации данных и статистики стало ясно, что линейные модели в нашем случае не подойдут. Так, мы решили попробовать Деревья Решений (Decision Trees).
Перед тем как перейти к главной части напомним, что в обучающей выборке были признаки – значения переменных, на которых и обучается модель, а также целевая переменная, что относит конкретный случай к тому или иному классу (выплата или невыплата).
Суть подхода решающего дерева заключается в следующем: в процессе обучения дерево находит самые значительные признаки, которые больше всего уменьшают информационную энтропию, следовательно максимизируют метрику information gain (разница энтропии до разбиения и после). Так, например, определив сначала ежегодный доход энтропия снизится больше, чем если бы сначала определяли цель заемщика. Каждое разбиение порождает 2 класса, в каждом из которых выявляется преобладающее число того или иного значения целевой переменной.
Тем не менее, оптимальное обучение дерева – сложная задача. Принцип машинного обучения заключается в выявлении общих, порой очень сложных, закономерностей, а не в простом «запоминании» случаев. Здесь нам пришлось столкнуться с переобучением. Модель безупречно классифицировала на обучающей выборке, но на тестовой проявляла себя гораздо хуже. Так мы решили применить кросс-валидацию и подбор параметров. Принцип кросс-валидации заключается в том, что мы разбиваем обучающую выборку на несколько подвыборок так, что каждая в процессе обучения будет единожды тестовой и обучающей в остальных случаях. Благодаря этому модель «запоминает» датафрейм меньше. Также, важно правильно подобрать параметры: глубину дерева, минимальное количества признаков в листе
19
для разбиения, максимальное количество признаков в листе и др. Подобрав наилучшие параметры, мы сделали модель лучше.
Однако любое дерево переобучается, что ухудшает качество модели. Так, мы остановились на финальном решении – Случайный лес (Random Forest). Модель состоит из нескольких деревьев решений с одинаковыми подобранными параметрами, но для каждого дерева на вход поступает случайная подвыборка обучающего датафрейма. Так, каждое дерево будет иметь частное переобучение, но поскольку итоговым результатом будут усредненные результаты деревьев, то модель получится лучше.
